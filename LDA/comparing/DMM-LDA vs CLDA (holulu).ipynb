{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('/Users/shinbo/PycharmProjects/paper/LDA')\n",
    "\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "def TOP_N_WORDS_df(MODEL, TOP_N_WORDS, col_names):\n",
    "    DMM_LDA_Top_words = pd.DataFrame()\n",
    "    for i in range(4):\n",
    "        temp = pd.DataFrame({'words':cv.get_feature_names(), 'lambda':MODEL.components_[i,:]})\n",
    "        temp = temp.sort_values(by='lambda', ascending=False).iloc[:TOP_N_WORDS,:]\n",
    "        DMM_LDA_Top_words[i] = temp['words'].tolist()\n",
    "    DMM_LDA_Top_words.columns = col_names\n",
    "    return DMM_LDA_Top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "dir_ = '/Users/shinbo/Desktop/metting/LDA/0. data/JH_data/JH_data_cleaned.pkl'\n",
    "\n",
    "data = pickle.load(open(dir_, 'rb'))\n",
    "stop_words = ['good','great','go','get','place']\n",
    "for i in range(len(data)):\n",
    "    data[i] = [w for w in data[i] if w not in stop_words]\n",
    "\n",
    "data_join = [' '.join(doc) for doc in data]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data_join).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMM-LDA Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "food 2458.24 | restaurant 1322.13 | service 1033.32 | price 768.9 | time 645.99 | try 633.13 | dish 610.3 | order 576.53 | make 569.66 | one 563.26 | meal 559.97 | come 542.81 | like 542.2 | menu 541.59 | eat 518.95 | lunch 481.02 | well 480.0 | fresh 463.18 | staff 460.67 | friendly 456.68 | \n",
      "\n",
      "Topic Nr.2:\n",
      "food 851.39 | order 658.84 | come 455.5 | time 394.55 | restaurant 377.43 | eat 350.38 | wait 344.93 | one 336.59 | table 327.83 | service 325.78 | take 324.96 | like 313.82 | back 307.02 | make 286.48 | menu 284.66 | well 236.98 | meal 228.13 | breakfast 217.76 | say 213.58 | look 212.93 | \n",
      "\n",
      "Topic Nr.3:\n",
      "food 1032.58 | service 499.35 | restaurant 429.52 | time 347.06 | one 321.48 | make 317.5 | well 289.85 | find 269.27 | best 267.86 | price 252.77 | dinner 246.43 | staff 235.08 | come 229.96 | delicious 225.85 | try 220.77 | back 218.66 | like 216.83 | enjoy 214.27 | menu 204.92 | love 204.63 | \n",
      "\n",
      "Topic Nr.4:\n",
      "food 887.19 | order 616.05 | like 555.55 | chicken 537.41 | one 527.06 | restaurant 421.33 | price 418.26 | service 386.94 | try 373.3 | also 369.12 | salad 368.57 | time 361.81 | well 350.56 | make 331.75 | rice 329.8 | back 321.22 | eat 306.77 | come 303.13 | delicious 299.99 | take 285.62 | \n"
     ]
    }
   ],
   "source": [
    "dir_model = f'/Users/shinbo/Desktop/metting/LDA/0. data/JH_data/result_4_topics.pkl'\n",
    "DMM_LDA = pickle.load(open(dir_model,'rb'))\n",
    "TOP_N_WORDS = 100\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "\n",
    "DMM_LDA_lam =  [DMM_LDA.components_[k,:] for k in range(4)]\n",
    "print_top_words(DMM_LDA_lam, list(cv.get_feature_names()), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_WORDS = 100\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6151.6169339328235,\n",
       " 5364.355225616776,\n",
       " 5362.65730105442,\n",
       " 5361.525234035369,\n",
       " 5361.4885118276825,\n",
       " 5361.488380038819]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMM_LDA.perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMM-CLDA Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food</td>\n",
       "      <td>service</td>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price</td>\n",
       "      <td>serve</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>staff</td>\n",
       "      <td>dinner</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>friendly</td>\n",
       "      <td>coffee</td>\n",
       "      <td>close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>value</td>\n",
       "      <td>check</td>\n",
       "      <td>drink</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pay</td>\n",
       "      <td>offer</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cheap</td>\n",
       "      <td>parking</td>\n",
       "      <td>lunch</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expensive</td>\n",
       "      <td>manager</td>\n",
       "      <td>tea</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>time</td>\n",
       "      <td>helpful</td>\n",
       "      <td>water</td>\n",
       "      <td>balcony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reasonably</td>\n",
       "      <td>help</td>\n",
       "      <td>cafe</td>\n",
       "      <td>lobby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>courteous</td>\n",
       "      <td>fruit</td>\n",
       "      <td>elevator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pricey</td>\n",
       "      <td>pool</td>\n",
       "      <td>coconut</td>\n",
       "      <td>towel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>charge</td>\n",
       "      <td>valet</td>\n",
       "      <td>beverage</td>\n",
       "      <td>bathrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cost</td>\n",
       "      <td>desk</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>order</td>\n",
       "      <td>welcoming</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rate</td>\n",
       "      <td>towels</td>\n",
       "      <td>beverages</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fee</td>\n",
       "      <td>solve</td>\n",
       "      <td>cafes</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>try</td>\n",
       "      <td>food</td>\n",
       "      <td>service</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cheaper</td>\n",
       "      <td>order</td>\n",
       "      <td>one</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>paid</td>\n",
       "      <td>come</td>\n",
       "      <td>make</td>\n",
       "      <td>try</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1    Topic 2      Topic 3     Topic 4\n",
       "0         food    service         food        food\n",
       "1        price      serve   restaurant    location\n",
       "2   restaurant      staff       dinner        stay\n",
       "3      service   friendly       coffee       close\n",
       "4        value      check        drink       front\n",
       "5          pay      offer    breakfast         far\n",
       "6        cheap    parking        lunch    bathroom\n",
       "7    expensive    manager          tea       order\n",
       "8         time    helpful        water     balcony\n",
       "9   reasonably       help         cafe       lobby\n",
       "10       money  courteous        fruit    elevator\n",
       "11      pricey       pool      coconut       towel\n",
       "12      charge      valet     beverage   bathrooms\n",
       "13        cost       desk    starbucks        like\n",
       "14       order  welcoming  restaurants         one\n",
       "15        rate     towels    beverages     chicken\n",
       "16         fee      solve        cafes  restaurant\n",
       "17         try       food      service        time\n",
       "18     cheaper      order          one     service\n",
       "19        paid       come         make         try"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_model = '/Users/shinbo/PycharmProjects/model_lda/HOL/CDMM_result_800_stop_words_holulu.pkl'\n",
    "DMM_CLDA = pickle.load(open(dir_model,'rb'))\n",
    "DMM_CLDA_lam =  [DMM_CLDA.components_[k,:] for k in range(4)]\n",
    "TOP_N_WORDS = 100\n",
    "DMM_CLDA_Top_words = TOP_N_WORDS_df(DMM_CLDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "DMM_CLDA_Top_words.iloc[:20,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9583.259897289177,\n",
       " 7860.4060265047665,\n",
       " 7825.5108801118595,\n",
       " 7803.606333616812,\n",
       " 7797.880270478682,\n",
       " 7795.743914528182,\n",
       " 7791.14747563514,\n",
       " 7789.870789021993,\n",
       " 7789.643356681828,\n",
       " 7789.643354936834]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMM_CLDA.perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "def top_20_words_for_topics(CLDA_lam,CDMM, aux=None, n=50):\n",
    "    if aux is True:\n",
    "        K = len(CLDA_lam)-1\n",
    "    else:\n",
    "        K = len(CLDA_lam)\n",
    "    words = {}\n",
    "    unique_words = []\n",
    "    for k in range(K):\n",
    "        CLDA_lam_word = pd.DataFrame({'word':cv.get_feature_names(), 'lam':CDMM.components_[k,:] }).sort_values(by='lam', ascending=False)\n",
    "        top_words = CLDA_lam_word.iloc[:n,:]['word'].tolist()\n",
    "        words[k] = CLDA_lam_word.iloc[:n,:].set_index('word').to_dict()['lam']\n",
    "        unique_words += top_words\n",
    "        \n",
    "    c = Counter(unique_words)\n",
    "    words_all_appear = []\n",
    "    for k,v in c.items():\n",
    "        if v == K:\n",
    "            words_all_appear.append(k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    words_degree = []\n",
    "    for k in range(K):\n",
    "        for w,d in words[k].items():\n",
    "            if w in words_all_appear:\n",
    "                words_degree.append(d)\n",
    "        \n",
    "    return words_all_appear, len(set(unique_words)) / (K*n), len(set(unique_words)) , np.mean(words_degree)\n",
    "words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(DMM_LDA_lam,DMM_LDA, n=50)\n",
    "uq_words_ratio, uq_words_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.57, 114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(DMM_CLDA_lam,DMM_CLDA, n=50)\n",
    "uq_words_ratio, uq_words_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n 변화시켜가며 비율 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varying_n(lam,mod):\n",
    "    result = {}\n",
    "    for n in range(10,51,10):\n",
    "        words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(lam, mod, n=n)\n",
    "        result[n] = (uq_words_ratio, uq_words_nums)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: (0.5, 20),\n",
       " 20: (0.4625, 37),\n",
       " 30: (0.45, 54),\n",
       " 40: (0.4125, 66),\n",
       " 50: (0.39, 78)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_n(DMM_LDA_lam,DMM_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinbo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/shinbo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: (0.9, 36),\n",
       " 20: (0.8375, 67),\n",
       " 30: (0.6833333333333333, 82),\n",
       " 40: (0.61875, 99),\n",
       " 50: (0.57, 114)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_n(DMM_CLDA_lam,DMM_CLDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove 벡터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "glove_dir = '/Users/shinbo/Desktop/metting/LDA/paper/word_embedding/glove.6B/glove.6B.100d.txt'\n",
    "word2glove = {}\n",
    "with open(glove_dir, encoding=\"utf8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        word_vector = line.split() # 각 줄을 읽어와서 word_vector에 저장.\n",
    "        word = word_vector[0] # word_vector에서 첫번째 값만 저장\n",
    "        word2glove[word] = np.array([float(i) for i in word_vector[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "TOP_N_WORDS = 10\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "DMM_CLDA_Top_words = TOP_N_WORDS_df(DMM_CLDA, TOP_N_WORDS, ['price','service','food','accomodation'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 21.872375379888407\n",
      "Topic 2 22.47562009205711\n",
      "Topic 3 25.758627516870614\n",
      "Topic 4 21.054852017700256\n",
      "\n",
      "price 19.692479310674916\n",
      "service 18.561523745732725\n",
      "food 24.306535028088533\n",
      "accomodation 17.68359948225043\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "# 하나의 토픽 내에서 nC2\n",
    "# 큰 값이 좋은 것임\n",
    "def cosine_sim(df):\n",
    "    for col in df.columns:\n",
    "        cos_val = 0\n",
    "        words = df[col].tolist()\n",
    "        for c in combinations(words,2):\n",
    "#             print(c)\n",
    "            cos_val += 1-cosine(word2glove[c[0]], word2glove[c[1]])\n",
    "#             print(c)\n",
    "#             print(cosine(word2glove[c[0]], word2glove[c[1]]))\n",
    "        print(col, cos_val)\n",
    "cosine_sim(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 160.65672745128927\n",
      "Topic 2 158.89858022254487\n",
      "Topic 3 166.41538963266825\n",
      "Topic 4 157.73314261930278\n",
      "\n",
      "price 113.85730698855456\n",
      "service 107.91229207469563\n",
      "food 102.85794865257414\n",
      "accomodation 108.9873472334934\n"
     ]
    }
   ],
   "source": [
    "# 토픽별로 cross similarity\n",
    "# 작은 값이 좋은 것임\n",
    "def cosine_sim_cross_topic(df):\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        cos_val = 0\n",
    "        target_words = df[col].tolist()\n",
    "        rest_cols = list(set(cols) - set([col]))\n",
    "        for not_col in rest_cols:\n",
    "#             print(col, not_col)\n",
    "            cross_words = df[not_col].tolist()\n",
    "            for target_word in target_words:\n",
    "                for cross_word in cross_words:\n",
    "#                     print(target_word, cross_word)\n",
    "                    cos_val += 1-cosine(word2glove[target_word],\n",
    "                               word2glove[cross_word])\n",
    "        print(col, cos_val)\n",
    "cosine_sim_cross_topic(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_cross_topic(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_dir = '/Users/shinbo/Desktop/metting/LDA/paper/word_embedding/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "word2vec_model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\n",
    "    w2v_dir, binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 6.81068236194551\n",
      "Topic 2 7.4617720246315\n",
      "Topic 3 6.506621167063713\n",
      "Topic 4 6.417552722617984\n",
      "27.196628276258707\n",
      "\n",
      "price 7.411576837301254\n",
      "service 6.9898152351379395\n",
      "food 16.137065947055817\n",
      "accomodation 5.366100776940584\n",
      "35.904558796435595\n"
     ]
    }
   ],
   "source": [
    "# 하나의 토픽 내에서 nC2\n",
    "# 큰 값이 좋은 것임\n",
    "def cosine_sim_w2v(df):\n",
    "    total = 0\n",
    "    for col in df.columns:\n",
    "        cos_val = 0\n",
    "        words = df[col].tolist()\n",
    "        for c in combinations(words,2):\n",
    "#             print(c)\n",
    "            cos_val += 1-cosine(word2vec_model.get_vector(c[0]),\n",
    "                               word2vec_model.get_vector(c[1]))\n",
    "#             print(c)\n",
    "#             print(cosine(word2glove[c[0]], word2glove[c[1]]))\n",
    "        print(col, cos_val)\n",
    "        total += cos_val\n",
    "    print(total)\n",
    "cosine_sim_w2v(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_w2v(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 62.905876487493515\n",
      "Topic 2 60.25979792140424\n",
      "Topic 3 58.78958444669843\n",
      "Topic 4 59.17897048778832\n",
      "241.1342293433845\n",
      "\n",
      "price 40.90699869324453\n",
      "service 32.94442398485262\n",
      "food 40.108993045054376\n",
      "accomodation 36.398743920377456\n",
      "150.35915964352898\n"
     ]
    }
   ],
   "source": [
    "# 토픽별로 cross similarity\n",
    "# 작은 값이 좋은 것임\n",
    "def cosine_sim_w2v_cross_topic(df):\n",
    "    total = 0\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        cos_val = 0\n",
    "        target_words = df[col].tolist()\n",
    "        rest_cols = list(set(cols) - set([col]))\n",
    "        for not_col in rest_cols:\n",
    "#             print(col, not_col)\n",
    "            cross_words = df[not_col].tolist()\n",
    "            for target_word in target_words:\n",
    "                for cross_word in cross_words:\n",
    "#                     print(target_word, cross_word)\n",
    "                    cos_val += 1-cosine(word2vec_model.get_vector(target_word),\n",
    "                               word2vec_model.get_vector(cross_word))\n",
    "        print(col, cos_val)\n",
    "        total += cos_val\n",
    "    print(total)\n",
    "cosine_sim_w2v_cross_topic(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_w2v_cross_topic(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
