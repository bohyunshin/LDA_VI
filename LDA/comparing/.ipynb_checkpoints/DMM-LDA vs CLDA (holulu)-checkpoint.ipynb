{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('/Users/shinbo/PycharmProjects/paper/LDA')\n",
    "\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "def TOP_N_WORDS_df(MODEL, TOP_N_WORDS, col_names):\n",
    "    DMM_LDA_Top_words = pd.DataFrame()\n",
    "    for i in range(4):\n",
    "        temp = pd.DataFrame({'words':cv.get_feature_names(), 'lambda':MODEL.components_[i,:]})\n",
    "        temp = temp.sort_values(by='lambda', ascending=False).iloc[:TOP_N_WORDS,:]\n",
    "        DMM_LDA_Top_words[i] = temp['words'].tolist()\n",
    "    DMM_LDA_Top_words.columns = col_names\n",
    "    return DMM_LDA_Top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "dir_ = '/Users/shinbo/Desktop/metting/LDA/0. data/JH_data/JH_data_cleaned.pkl'\n",
    "\n",
    "data = pickle.load(open(dir_, 'rb'))\n",
    "stop_words = ['hotel','stay','room','waikiki']\n",
    "for i in range(len(data)):\n",
    "    data[i] = [w for w in data[i] if w not in stop_words]\n",
    "\n",
    "data_join = [' '.join(doc) for doc in data]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data_join).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMM-LDA Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c7971f9cf12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDMM_LDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTOP_N_WORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDMM_LDA_Top_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOP_N_WORDS_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDMM_LDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOP_N_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'Topic {i}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDMM_LDA_lam\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mDMM_LDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b5d311d5c37a>\u001b[0m in \u001b[0;36mTOP_N_WORDS_df\u001b[0;34m(MODEL, TOP_N_WORDS, col_names)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mDMM_LDA_Top_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lambda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTOP_N_WORDS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mDMM_LDA_Top_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "dir_model = f'/Users/shinbo/Desktop/metting/LDA/0. data/JH_data/result_4_topics.pkl'\n",
    "DMM_LDA = pickle.load(open(dir_model,'rb'))\n",
    "TOP_N_WORDS = 100\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "\n",
    "DMM_LDA_lam =  [DMM_LDA.components_[k,:] for k in range(4)]\n",
    "print_top_words(DMM_LDA_lam, list(cv.get_feature_names()), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_WORDS = 100\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beach</td>\n",
       "      <td>beach</td>\n",
       "      <td>staff</td>\n",
       "      <td>beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>pool</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>staff</td>\n",
       "      <td>view</td>\n",
       "      <td>time</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location</td>\n",
       "      <td>great</td>\n",
       "      <td>make</td>\n",
       "      <td>pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean</td>\n",
       "      <td>get</td>\n",
       "      <td>view</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>friendly</td>\n",
       "      <td>nice</td>\n",
       "      <td>check</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>staff</td>\n",
       "      <td>beach</td>\n",
       "      <td>resort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>walk</td>\n",
       "      <td>bed</td>\n",
       "      <td>service</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>day</td>\n",
       "      <td>go</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nice</td>\n",
       "      <td>good</td>\n",
       "      <td>night</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>view</td>\n",
       "      <td>one</td>\n",
       "      <td>get</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>helpful</td>\n",
       "      <td>night</td>\n",
       "      <td>friendly</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>location</td>\n",
       "      <td>day</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service</td>\n",
       "      <td>check</td>\n",
       "      <td>one</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>night</td>\n",
       "      <td>clean</td>\n",
       "      <td>front</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>close</td>\n",
       "      <td>time</td>\n",
       "      <td>pool</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shop</td>\n",
       "      <td>ocean</td>\n",
       "      <td>place</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>well</td>\n",
       "      <td>floor</td>\n",
       "      <td>nice</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pool</td>\n",
       "      <td>small</td>\n",
       "      <td>desk</td>\n",
       "      <td>ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>place</td>\n",
       "      <td>also</td>\n",
       "      <td>like</td>\n",
       "      <td>tower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1   Topic 2   Topic 3     Topic 4\n",
       "0        beach     beach     staff       beach\n",
       "1        great      pool     great       great\n",
       "2        staff      view      time        view\n",
       "3     location     great      make        pool\n",
       "4        clean       get      view    location\n",
       "5     friendly      nice     check        good\n",
       "6         good     staff     beach      resort\n",
       "7         walk       bed   service  restaurant\n",
       "8   restaurant       day        go        time\n",
       "9         nice      good     night       place\n",
       "10        view       one       get         get\n",
       "11     helpful     night  friendly       staff\n",
       "12   breakfast  location       day          go\n",
       "13     service     check       one        walk\n",
       "14       night     clean     front        nice\n",
       "15       close      time      pool       night\n",
       "16        shop     ocean     place         one\n",
       "17        well     floor      nice         day\n",
       "18        pool     small      desk       ocean\n",
       "19       place      also      like       tower"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMM_LDA_Top_words.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMM-CLDA Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pay</td>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price</td>\n",
       "      <td>check</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fee</td>\n",
       "      <td>service</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charge</td>\n",
       "      <td>pool</td>\n",
       "      <td>food</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rate</td>\n",
       "      <td>friendly</td>\n",
       "      <td>great</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>money</td>\n",
       "      <td>desk</td>\n",
       "      <td>coffee</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>value</td>\n",
       "      <td>helpful</td>\n",
       "      <td>water</td>\n",
       "      <td>pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expensive</td>\n",
       "      <td>valet</td>\n",
       "      <td>drink</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cost</td>\n",
       "      <td>help</td>\n",
       "      <td>dinner</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cheap</td>\n",
       "      <td>offer</td>\n",
       "      <td>fruit</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reasonably</td>\n",
       "      <td>manager</td>\n",
       "      <td>tea</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pricey</td>\n",
       "      <td>parking</td>\n",
       "      <td>coconut</td>\n",
       "      <td>close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cheaper</td>\n",
       "      <td>serve</td>\n",
       "      <td>cafe</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paid</td>\n",
       "      <td>courteous</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>night</td>\n",
       "      <td>welcoming</td>\n",
       "      <td>beverage</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>staff</td>\n",
       "      <td>solve</td>\n",
       "      <td>make</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>get</td>\n",
       "      <td>towels</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>good</td>\n",
       "      <td>serviced</td>\n",
       "      <td>cafes</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day</td>\n",
       "      <td>offered</td>\n",
       "      <td>beverages</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>beach</td>\n",
       "      <td>solved</td>\n",
       "      <td>fruits</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1    Topic 2      Topic 3     Topic 4\n",
       "0          pay      staff        staff       beach\n",
       "1        price      check    breakfast       great\n",
       "2          fee    service   restaurant    location\n",
       "3       charge       pool         food       staff\n",
       "4         rate   friendly        great        view\n",
       "5        money       desk       coffee        good\n",
       "6        value    helpful        water        pool\n",
       "7    expensive      valet        drink        nice\n",
       "8         cost       help       dinner        walk\n",
       "9        cheap      offer        fruit       clean\n",
       "10  reasonably    manager          tea  restaurant\n",
       "11      pricey    parking      coconut       close\n",
       "12     cheaper      serve         cafe       night\n",
       "13        paid  courteous    starbucks    friendly\n",
       "14       night  welcoming     beverage         get\n",
       "15       staff      solve         make        time\n",
       "16         get     towels  restaurants         one\n",
       "17        good   serviced        cafes       place\n",
       "18         day    offered    beverages       front\n",
       "19       beach     solved       fruits         day"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_model = f'/Users/shinbo/PycharmProjects/model_lda/{type_}/CDMM_result_{type_}_800_stop_words.pkl'\n",
    "DMM_CLDA = pickle.load(open(dir_model,'rb'))\n",
    "DMM_CLDA_lam =  [DMM_CLDA.components_[k,:] for k in range(4)]\n",
    "TOP_N_WORDS = 100\n",
    "DMM_CLDA_Top_words = TOP_N_WORDS_df(DMM_CLDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "DMM_CLDA_Top_words.iloc[:20,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43, 86)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "def top_20_words_for_topics(CLDA_lam,CDMM, aux=None, n=50):\n",
    "    if aux is True:\n",
    "        K = len(CLDA_lam)-1\n",
    "    else:\n",
    "        K = len(CLDA_lam)\n",
    "    words = {}\n",
    "    unique_words = []\n",
    "    for k in range(K):\n",
    "        CLDA_lam_word = pd.DataFrame({'word':cv.get_feature_names(), 'lam':CDMM.components_[k,:] }).sort_values(by='lam', ascending=False)\n",
    "        top_words = CLDA_lam_word.iloc[:n,:]['word'].tolist()\n",
    "        words[k] = CLDA_lam_word.iloc[:n,:].set_index('word').to_dict()['lam']\n",
    "        unique_words += top_words\n",
    "        \n",
    "    c = Counter(unique_words)\n",
    "    words_all_appear = []\n",
    "    for k,v in c.items():\n",
    "        if v == K:\n",
    "            words_all_appear.append(k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    words_degree = []\n",
    "    for k in range(K):\n",
    "        for w,d in words[k].items():\n",
    "            if w in words_all_appear:\n",
    "                words_degree.append(d)\n",
    "        \n",
    "    return words_all_appear, len(set(unique_words)) / (K*n), len(set(unique_words)) , np.mean(words_degree)\n",
    "words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(DMM_LDA_lam,DMM_LDA, n=50)\n",
    "uq_words_ratio, uq_words_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.535, 107)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(DMM_CLDA_lam,DMM_CLDA, n=50)\n",
    "uq_words_ratio, uq_words_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n 변화시켜가며 비율 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varying_n(lam,mod):\n",
    "    result = {}\n",
    "    for n in range(10,51,10):\n",
    "        words_, uq_words_ratio, uq_words_nums, asso_deg = top_20_words_for_topics(lam, mod, n=n)\n",
    "        result[n] = (uq_words_ratio, uq_words_nums)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: (0.575, 23),\n",
       " 20: (0.4625, 37),\n",
       " 30: (0.4166666666666667, 50),\n",
       " 40: (0.4375, 70),\n",
       " 50: (0.43, 86)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_n(DMM_LDA_lam,DMM_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinbo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/shinbo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: (0.9, 36),\n",
       " 20: (0.85, 68),\n",
       " 30: (0.65, 78),\n",
       " 40: (0.575, 92),\n",
       " 50: (0.535, 107)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_n(DMM_CLDA_lam,DMM_CLDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove 벡터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "glove_dir = '/Users/shinbo/Desktop/metting/LDA/paper/word_embedding/glove.6B/glove.6B.100d.txt'\n",
    "word2glove = {}\n",
    "with open(glove_dir, encoding=\"utf8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        word_vector = line.split() # 각 줄을 읽어와서 word_vector에 저장.\n",
    "        word = word_vector[0] # word_vector에서 첫번째 값만 저장\n",
    "        word2glove[word] = np.array([float(i) for i in word_vector[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "TOP_N_WORDS = 10\n",
    "DMM_LDA_Top_words = TOP_N_WORDS_df(DMM_LDA, TOP_N_WORDS, [f'Topic {i}' for i in range(1,5)])\n",
    "DMM_CLDA_Top_words = TOP_N_WORDS_df(DMM_CLDA, TOP_N_WORDS, ['price','service','food','accomodation'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 18.30634151716085\n",
      "Topic 2 20.692595438908235\n",
      "Topic 3 22.837739656762945\n",
      "Topic 4 21.904842424916218\n",
      "\n",
      "price 24.96277772064167\n",
      "service 15.167980320395671\n",
      "food 19.916207420563286\n",
      "accomodation 18.910066678221664\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "# 하나의 토픽 내에서 nC2\n",
    "# 큰 값이 좋은 것임\n",
    "def cosine_sim(df):\n",
    "    for col in df.columns:\n",
    "        cos_val = 0\n",
    "        words = df[col].tolist()\n",
    "        for c in combinations(words,2):\n",
    "#             print(c)\n",
    "            cos_val += 1-cosine(word2glove[c[0]], word2glove[c[1]])\n",
    "#             print(c)\n",
    "#             print(cosine(word2glove[c[0]], word2glove[c[1]]))\n",
    "        print(col, cos_val)\n",
    "cosine_sim(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 139.98899849327404\n",
      "Topic 2 146.08137672283598\n",
      "Topic 3 146.14787236591394\n",
      "Topic 4 145.08204242019235\n",
      "\n",
      "price 102.36063631059507\n",
      "service 103.7089664140839\n",
      "food 100.42500140438251\n",
      "accomodation 107.43641007958198\n"
     ]
    }
   ],
   "source": [
    "# 토픽별로 cross similarity\n",
    "# 작은 값이 좋은 것임\n",
    "def cosine_sim_cross_topic(df):\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        cos_val = 0\n",
    "        target_words = df[col].tolist()\n",
    "        rest_cols = list(set(cols) - set([col]))\n",
    "        for not_col in rest_cols:\n",
    "#             print(col, not_col)\n",
    "            cross_words = df[not_col].tolist()\n",
    "            for target_word in target_words:\n",
    "                for cross_word in cross_words:\n",
    "#                     print(target_word, cross_word)\n",
    "                    cos_val += 1-cosine(word2glove[target_word],\n",
    "                               word2glove[cross_word])\n",
    "        print(col, cos_val)\n",
    "cosine_sim_cross_topic(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_cross_topic(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_dir = '/Users/shinbo/Desktop/metting/LDA/paper/word_embedding/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "word2vec_model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\n",
    "    w2v_dir, binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 7.984154678881168\n",
      "Topic 2 7.517229728400707\n",
      "Topic 3 5.78228657389991\n",
      "Topic 4 6.976437824778259\n",
      "\n",
      "price 12.934732601046562\n",
      "service 6.8256479278206825\n",
      "food 10.725641672033817\n",
      "accomodation 7.000471843406558\n"
     ]
    }
   ],
   "source": [
    "# 하나의 토픽 내에서 nC2\n",
    "# 큰 값이 좋은 것임\n",
    "def cosine_sim_w2v(df):\n",
    "    for col in df.columns:\n",
    "        cos_val = 0\n",
    "        words = df[col].tolist()\n",
    "        for c in combinations(words,2):\n",
    "#             print(c)\n",
    "            cos_val += 1-cosine(word2vec_model.get_vector(c[0]),\n",
    "                               word2vec_model.get_vector(c[1]))\n",
    "#             print(c)\n",
    "#             print(cosine(word2glove[c[0]], word2glove[c[1]]))\n",
    "        print(col, cos_val)\n",
    "cosine_sim_w2v(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_w2v(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 57.16011403314769\n",
      "Topic 2 58.74213494709693\n",
      "Topic 3 52.35971114039421\n",
      "Topic 4 55.431902976939455\n",
      "\n",
      "price 31.277103207539767\n",
      "service 39.33417551475577\n",
      "food 35.5444508001674\n",
      "accomodation 39.11769031314179\n"
     ]
    }
   ],
   "source": [
    "# 토픽별로 cross similarity\n",
    "# 작은 값이 좋은 것임\n",
    "def cosine_sim_w2v_cross_topic(df):\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        cos_val = 0\n",
    "        target_words = df[col].tolist()\n",
    "        rest_cols = list(set(cols) - set([col]))\n",
    "        for not_col in rest_cols:\n",
    "#             print(col, not_col)\n",
    "            cross_words = df[not_col].tolist()\n",
    "            for target_word in target_words:\n",
    "                for cross_word in cross_words:\n",
    "#                     print(target_word, cross_word)\n",
    "                    cos_val += 1-cosine(word2vec_model.get_vector(target_word),\n",
    "                               word2vec_model.get_vector(cross_word))\n",
    "        print(col, cos_val)\n",
    "cosine_sim_w2v_cross_topic(DMM_LDA_Top_words)\n",
    "print()\n",
    "cosine_sim_w2v_cross_topic(DMM_CLDA_Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open('/Users/shinbo/Desktop/metting/LDA/0. data/JH_data/JH_data_cleaned.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'taste',\n",
       " 'simple',\n",
       " 'dish',\n",
       " 'never',\n",
       " 'try',\n",
       " 'poke',\n",
       " 'wow',\n",
       " 'go',\n",
       " 'spicy',\n",
       " 'dish',\n",
       " 'excellent',\n",
       " 'discourage',\n",
       " 'way',\n",
       " 'look',\n",
       " 'outside',\n",
       " 'truly',\n",
       " 'hole',\n",
       " 'wall',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'plan',\n",
       " 'go',\n",
       " 'go',\n",
       " 'back',\n",
       " 'home']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
