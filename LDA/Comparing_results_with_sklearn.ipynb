{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "cv = CountVectorizer()\n",
    "_dir = \"/Users/shinbo/Desktop/metting/LDA/0. data/20news-bydate/newsgroup_preprocessed_corpus.pickle\"\n",
    "\n",
    "\n",
    "class LDA_sklearn:\n",
    "    def __init__(self, path_data, alpha, eta, K):\n",
    "        # loading data\n",
    "        self.data = pickle.load(open(path_data, 'rb'))\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.choice(len(self.data), 1000, replace=False)\n",
    "        self.data = [j for i, j in enumerate(self.data) if i in idx]\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "\n",
    "    def _make_vocab(self):\n",
    "        self.vocab = []\n",
    "        for lst in self.data:\n",
    "            self.vocab += lst\n",
    "        self.vocab = sorted(list(set(self.vocab)))\n",
    "        self.w2idx = {j: i for i, j in enumerate(self.vocab)}\n",
    "        self.idx2w = {val: key for key, val in self.w2idx.items()}\n",
    "        self.doc2idx = [[self.w2idx[word] for word in doc] for doc in self.data]\n",
    "        self.data = [' '.join(doc) for doc in self.data]\n",
    "\n",
    "    def _cv(self):\n",
    "        self._make_vocab()\n",
    "        self.cv = CountVectorizer()\n",
    "        self.df = self.cv.fit_transform(self.data)\n",
    "\n",
    "    def _train(self):\n",
    "        self._make_vocab\n",
    "        self._cv()\n",
    "        lda = LatentDirichletAllocation(n_components=self.K, \n",
    "                                        doc_topic_prior=self.alpha, topic_word_prior=self.eta,\n",
    "                                        learning_method='batch', max_iter=1000)\n",
    "        lda.fit(self.df)\n",
    "        return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA_sklearn(_dir, 5, 0.1, 10)\n",
    "result = lda._train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result with sklearn lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "right 245.64 | state 161.44 | well 141.33 | ca 138.66 | people 124.58 | israel 102.1 | second 89.7 | father 87.1 | israeli 84.1 | use 82.95 | \n",
      "\n",
      "Topic Nr.2:\n",
      "game 161.1 | university 128.27 | de 77.78 | year 64.98 | new 61.01 | anyone 59.18 | go 58.27 | please 56.13 | canada 52.95 | last 51.8 | \n",
      "\n",
      "Topic Nr.3:\n",
      "key 159.65 | time 128.4 | gun 111.18 | think 102.61 | use 85.0 | system 83.31 | attack 79.3 | risk 64.1 | death 62.45 | like 60.54 | \n",
      "\n",
      "Topic Nr.4:\n",
      "go 377.8 | come 138.62 | get 130.5 | know 130.05 | look 93.52 | take 82.07 | car 79.02 | well 77.29 | still 75.45 | want 74.71 | \n",
      "\n",
      "Topic Nr.5:\n",
      "get 147.92 | space 125.47 | science 96.2 | use 79.17 | high 73.8 | know 68.83 | make 63.45 | technology 61.47 | new 60.95 | also 60.93 | \n",
      "\n",
      "Topic Nr.6:\n",
      "year 141.71 | university 134.33 | good 106.19 | team 104.37 | get 93.07 | win 91.84 | player 88.27 | computer 85.5 | distribution 78.42 | well 69.65 | \n",
      "\n",
      "Topic Nr.7:\n",
      "window 281.28 | use 275.61 | mail 184.0 | get 166.6 | system 163.33 | program 162.65 | information 153.67 | list 139.31 | include 133.64 | work 130.53 | \n",
      "\n",
      "Topic Nr.8:\n",
      "god 270.23 | think 247.87 | people 223.34 | believe 203.1 | like 170.72 | make 160.4 | true 112.91 | thing 111.74 | know 109.81 | point 107.76 | \n",
      "\n",
      "Topic Nr.9:\n",
      "jpeg 243.1 | file 226.52 | image 215.08 | _o 197.1 | color 161.09 | gif 117.07 | ei 113.1 | um 111.1 | pa 108.1 | bit 97.52 | \n",
      "\n",
      "Topic Nr.10:\n",
      "drive 207.1 | card 127.1 | university 118.09 | get 106.01 | use 99.43 | disk 97.28 | hard 94.04 | problem 88.37 | find 76.2 | ra 75.25 | \n"
     ]
    }
   ],
   "source": [
    "lda_lam = [result.components_[i,:] for i in range(10)]\n",
    "\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda_lam, list(lda.cv.get_feature_names()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430.2962585206815"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1124795.5669155763"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.score(lda.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result with my lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "room 1201.1 | hotel 1130.31 | stay 960.16 | great 594.12 | staff 489.66 | clean 374.92 | location 338.84 | one 314.09 | service 309.45 | beach 308.85 | \n",
      "\n",
      "Topic Nr.2:\n",
      "room 2899.14 | hotel 2509.11 | stay 1685.79 | beach 1605.94 | view 1365.41 | great 1236.5 | waikiki 1080.26 | nice 910.01 | get 767.98 | pool 763.47 | \n",
      "\n",
      "Topic Nr.3:\n",
      "hotel 4344.5 | great 3830.73 | room 2871.35 | location 2616.8 | stay 2458.15 | beach 2190.62 | staff 2053.06 | good 1810.13 | nice 1328.09 | waikiki 1277.36 | \n",
      "\n",
      "Topic Nr.4:\n",
      "room 829.66 | stay 544.93 | staff 333.44 | view 293.14 | hotel 292.53 | get 256.11 | great 248.55 | location 225.47 | beach 205.38 | time 198.97 | \n",
      "\n",
      "Topic Nr.5:\n",
      "hotel 1599.98 | stay 1160.94 | room 867.11 | staff 829.19 | time 663.48 | great 449.11 | check 431.48 | get 422.04 | go 413.63 | make 381.85 | \n",
      "\n",
      "Topic Nr.6:\n",
      "hotel 1138.91 | room 991.07 | great 791.95 | staff 742.16 | beach 723.18 | stay 720.35 | waikiki 569.31 | location 556.7 | get 438.43 | friendly 356.59 | \n",
      "\n",
      "Topic Nr.7:\n",
      "hotel 3083.9 | room 2433.65 | stay 2093.37 | great 1368.93 | beach 1274.2 | waikiki 1257.21 | view 1160.78 | location 1053.46 | service 880.03 | staff 803.85 | \n",
      "\n",
      "Topic Nr.8:\n",
      "room 287.64 | good 109.11 | stay 103.2 | hotel 97.18 | staff 88.14 | view 86.15 | great 78.28 | place 70.2 | location 65.19 | get 60.13 | \n",
      "\n",
      "Topic Nr.9:\n",
      "hotel 2092.2 | stay 1719.47 | great 1341.02 | staff 1297.11 | waikiki 1181.87 | room 1060.19 | beach 846.62 | location 698.42 | friendly 609.7 | service 567.46 | \n",
      "\n",
      "Topic Nr.10:\n",
      "hotel 1012.38 | room 880.08 | beach 779.55 | stay 623.65 | great 519.8 | pool 518.62 | waikiki 505.88 | view 442.63 | location 345.85 | nice 342.92 | \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "my_model = pickle.load(open('../../model_lda/DMM_result.pkl','rb'))\n",
    "\n",
    "data = pickle.load(open('preprocessed_review.pickle', 'rb'))\n",
    "data_join = [' '.join(doc) for doc in data]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data_join).toarray()\n",
    "\n",
    "lda_lam = [my_model.components_[k,:] for k in range(10)]\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda_lam, list(cv.get_feature_names()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53320008e+04, 5.00012733e+00, 5.00012733e+00, 5.00012733e+00,\n",
       "       6.99903117e+00, 5.00012733e+00, 5.00012733e+00, 5.00012733e+00,\n",
       "       5.99931584e+00, 5.00012733e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result with clda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "know 641.62 | think 555.67 | time 442.18 | well 402.65 | come 398.39 | see 318.61 | want 314.08 | right 301.04 | good 300.9 | also 299.48 | \n",
      "\n",
      "Topic Nr.2:\n",
      "know 403.55 | think 349.01 | time 315.98 | well 301.96 | see 291.1 | new 272.48 | good 271.17 | also 248.17 | right 226.62 | want 219.54 | \n",
      "\n",
      "Topic Nr.3:\n",
      "know 420.68 | think 388.19 | time 345.76 | well 320.28 | good 300.33 | db 288.96 | also 285.56 | see 266.77 | new 252.79 | system 239.3 | \n",
      "\n",
      "Topic Nr.4:\n",
      "know 399.28 | program 380.86 | system 361.73 | time 348.1 | also 347.11 | use 337.8 | think 327.47 | see 325.15 | good 303.81 | well 302.47 | \n",
      "\n",
      "Topic Nr.5:\n",
      "ax 9912.39 | max 698.08 | know 345.28 | think 316.79 | time 272.68 | di 271.5 | well 243.85 | good 239.87 | ei 236.36 | tm 230.21 | \n",
      "\n",
      "Topic Nr.6:\n",
      "know 382.9 | think 381.88 | time 305.24 | drive 304.21 | well 287.2 | system 286.87 | good 276.76 | also 267.32 | new 255.27 | see 254.51 | \n",
      "\n",
      "Topic Nr.7:\n",
      "know 404.52 | system 385.76 | also 360.93 | think 351.25 | time 348.9 | well 333.47 | see 307.23 | new 299.68 | use 288.44 | good 277.72 | \n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('/Users/shinbo/PycharmProjects/model/clda_newsgroup.pickle','rb'))\n",
    "\n",
    "data = pickle.load(open(_dir, 'rb'))\n",
    "data_join = [' '.join(doc) for doc in data]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data_join).toarray()\n",
    "\n",
    "lda_lam = [model.components_[k,:] for k in range(7)]\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda_lam, list(cv.get_feature_names()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89.52925916, 95.40932824, 18.34532888, ...,  1.09184158,\n",
       "         0.10767849,  0.10080052],\n",
       "       [44.09064436, 41.7864441 , 13.74226963, ...,  0.10143394,\n",
       "         2.08582988,  0.59588468],\n",
       "       [60.37497639, 32.13482869, 22.83849665, ...,  0.10144952,\n",
       "         0.10118269,  0.10057967],\n",
       "       ...,\n",
       "       [13.91398321,  6.12219929,  1.23121052, ...,  0.10153522,\n",
       "         0.10111832,  0.10060761],\n",
       "       [75.47577938, 75.47124745, 18.84751955, ...,  0.10169393,\n",
       "         0.10139479,  0.10081048],\n",
       "       [20.30630819, 16.55334175,  9.21009231, ...,  0.1010206 ,\n",
       "         0.10118058,  0.10067582]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': [4814,\n",
       "  50728,\n",
       "  39434,\n",
       "  4185,\n",
       "  39430,\n",
       "  19919,\n",
       "  19820,\n",
       "  4813,\n",
       "  20056,\n",
       "  30395,\n",
       "  56244],\n",
       " 'comp': [35932,\n",
       "  11526,\n",
       "  54423,\n",
       "  24553,\n",
       "  26230,\n",
       "  66698,\n",
       "  36993,\n",
       "  53839,\n",
       "  28432,\n",
       "  5346,\n",
       "  7106,\n",
       "  58537,\n",
       "  60089,\n",
       "  5207,\n",
       "  3656,\n",
       "  64728,\n",
       "  37067,\n",
       "  47772,\n",
       "  21259,\n",
       "  17178],\n",
       " 'misc': [19942,\n",
       "  36553,\n",
       "  13082,\n",
       "  29790,\n",
       "  18502,\n",
       "  42965,\n",
       "  12747,\n",
       "  47631,\n",
       "  45104,\n",
       "  54869,\n",
       "  12087,\n",
       "  34932,\n",
       "  54225,\n",
       "  53024,\n",
       "  45063,\n",
       "  6688,\n",
       "  9743,\n",
       "  63878,\n",
       "  43751,\n",
       "  4534,\n",
       "  43157,\n",
       "  7683,\n",
       "  54168,\n",
       "  22124,\n",
       "  25680],\n",
       " 'rec': [46404,\n",
       "  34095,\n",
       "  66678,\n",
       "  16723,\n",
       "  5527,\n",
       "  26907,\n",
       "  50029,\n",
       "  46409,\n",
       "  53713,\n",
       "  6921,\n",
       "  9298,\n",
       "  57571,\n",
       "  53953,\n",
       "  59584,\n",
       "  33849],\n",
       " 'sci': [56443,\n",
       "  53658,\n",
       "  10417,\n",
       "  29272,\n",
       "  18768,\n",
       "  16465,\n",
       "  14326,\n",
       "  26585,\n",
       "  42415,\n",
       "  32343,\n",
       "  11950,\n",
       "  11109],\n",
       " 'soc': [36319,\n",
       "  34748,\n",
       "  37033,\n",
       "  6444,\n",
       "  67125,\n",
       "  61802,\n",
       "  23891,\n",
       "  10556,\n",
       "  24147,\n",
       "  21332,\n",
       "  26199,\n",
       "  63894,\n",
       "  50064,\n",
       "  33954,\n",
       "  61767,\n",
       "  19767,\n",
       "  10539,\n",
       "  59249,\n",
       "  34693,\n",
       "  23620,\n",
       "  45376,\n",
       "  60298,\n",
       "  65995,\n",
       "  20545,\n",
       "  37403,\n",
       "  63247,\n",
       "  10634,\n",
       "  24170,\n",
       "  55355,\n",
       "  67109],\n",
       " 'talk': [21414,\n",
       "  10377,\n",
       "  62156,\n",
       "  62026,\n",
       "  25072,\n",
       "  68922,\n",
       "  4274,\n",
       "  67303,\n",
       "  59761,\n",
       "  31065,\n",
       "  30459,\n",
       "  9026,\n",
       "  30460,\n",
       "  39808,\n",
       "  32571]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheist',\n",
       "  'religion',\n",
       "  'morality',\n",
       "  'argument',\n",
       "  'moral',\n",
       "  'example',\n",
       "  'evidence',\n",
       "  'atheism',\n",
       "  'exist',\n",
       "  'islam',\n",
       "  'something'],\n",
       " 'comp': ['mac',\n",
       "  'color',\n",
       "  'set',\n",
       "  'graphic',\n",
       "  'help',\n",
       "  'window',\n",
       "  'max',\n",
       "  'scsi',\n",
       "  'image',\n",
       "  'ax',\n",
       "  'bit',\n",
       "  'support',\n",
       "  'thanks',\n",
       "  'available',\n",
       "  'anyone',\n",
       "  'version',\n",
       "  'mb',\n",
       "  'problem',\n",
       "  'file',\n",
       "  'driver'],\n",
       " 'misc': ['excellent',\n",
       "  'manual',\n",
       "  'cover',\n",
       "  'interested',\n",
       "  'email',\n",
       "  'offer',\n",
       "  'copy',\n",
       "  'price',\n",
       "  'pc',\n",
       "  'shipping',\n",
       "  'condition',\n",
       "  'list',\n",
       "  'send',\n",
       "  'sale',\n",
       "  'pay',\n",
       "  'best',\n",
       "  'cd',\n",
       "  'usa',\n",
       "  'original',\n",
       "  'ask',\n",
       "  'old',\n",
       "  'book',\n",
       "  'sell',\n",
       "  'forsale',\n",
       "  'hard'],\n",
       " 'rec': ['play',\n",
       "  'league',\n",
       "  'win',\n",
       "  'dod',\n",
       "  'back',\n",
       "  'hockey',\n",
       "  'really',\n",
       "  'player',\n",
       "  'score',\n",
       "  'bike',\n",
       "  'car',\n",
       "  'still',\n",
       "  'season',\n",
       "  'team',\n",
       "  'last'],\n",
       " 'sci': ['space',\n",
       "  'science',\n",
       "  'chip',\n",
       "  'information',\n",
       "  'encryption',\n",
       "  'distribution',\n",
       "  'data',\n",
       "  'high',\n",
       "  'number',\n",
       "  'key',\n",
       "  'computer',\n",
       "  'clipper'],\n",
       " 'soc': ['make',\n",
       "  'like',\n",
       "  'may',\n",
       "  'believe',\n",
       "  'work',\n",
       "  'truth',\n",
       "  'give',\n",
       "  'christianity',\n",
       "  'go',\n",
       "  'find',\n",
       "  'hell',\n",
       "  'use',\n",
       "  'reason',\n",
       "  'law',\n",
       "  'true',\n",
       "  'even',\n",
       "  'christ',\n",
       "  'take',\n",
       "  'life',\n",
       "  'get',\n",
       "  'people',\n",
       "  'thing',\n",
       "  'way',\n",
       "  'faith',\n",
       "  'mean',\n",
       "  'university',\n",
       "  'church',\n",
       "  'god',\n",
       "  'sin',\n",
       "  'word'],\n",
       " 'talk': ['first',\n",
       "  'child',\n",
       "  'two',\n",
       "  'turkish',\n",
       "  'gun',\n",
       "  'year',\n",
       "  'armenian',\n",
       "  'writes',\n",
       "  'tell',\n",
       "  'jew',\n",
       "  'israel',\n",
       "  'call',\n",
       "  'israeli',\n",
       "  'mr',\n",
       "  'kill']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_words = pickle.load(open('/Users/shinbo/Desktop/metting/LDA/0. data/20news-bydate/topics_top_words.pickle','rb'))\n",
    "seed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup = pickle.load(open('/Users/shinbo/Desktop/metting/LDA/0. data/20news-bydate/newsgroup_preprocessed_corpus.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 70094), 70094)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inverse = {j:i for i,j in cv.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 21414\n",
      "give 23891\n",
      "god 24170\n",
      "something 56244\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for k in seed_words.keys():\n",
    "    a += seed_words[k]\n",
    "\n",
    "for i in np.nonzero(X[0,:])[0]:\n",
    "    if vocab_inverse[i] in a:\n",
    "        print(vocab_inverse[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atheist',\n",
       " 'religion',\n",
       " 'morality',\n",
       " 'argument',\n",
       " 'moral',\n",
       " 'example',\n",
       " 'evidence',\n",
       " 'atheism',\n",
       " 'exist',\n",
       " 'islam',\n",
       " 'something',\n",
       " 'mac',\n",
       " 'color',\n",
       " 'set',\n",
       " 'graphic',\n",
       " 'help',\n",
       " 'window',\n",
       " 'max',\n",
       " 'scsi',\n",
       " 'image',\n",
       " 'ax',\n",
       " 'bit',\n",
       " 'support',\n",
       " 'thanks',\n",
       " 'available',\n",
       " 'anyone',\n",
       " 'version',\n",
       " 'mb',\n",
       " 'problem',\n",
       " 'file',\n",
       " 'driver',\n",
       " 'excellent',\n",
       " 'manual',\n",
       " 'cover',\n",
       " 'interested',\n",
       " 'email',\n",
       " 'offer',\n",
       " 'copy',\n",
       " 'price',\n",
       " 'pc',\n",
       " 'shipping',\n",
       " 'condition',\n",
       " 'list',\n",
       " 'send',\n",
       " 'sale',\n",
       " 'pay',\n",
       " 'best',\n",
       " 'cd',\n",
       " 'usa',\n",
       " 'original',\n",
       " 'ask',\n",
       " 'old',\n",
       " 'book',\n",
       " 'sell',\n",
       " 'forsale',\n",
       " 'hard',\n",
       " 'play',\n",
       " 'league',\n",
       " 'win',\n",
       " 'dod',\n",
       " 'back',\n",
       " 'hockey',\n",
       " 'really',\n",
       " 'player',\n",
       " 'score',\n",
       " 'bike',\n",
       " 'car',\n",
       " 'still',\n",
       " 'season',\n",
       " 'team',\n",
       " 'last',\n",
       " 'space',\n",
       " 'science',\n",
       " 'chip',\n",
       " 'information',\n",
       " 'encryption',\n",
       " 'distribution',\n",
       " 'data',\n",
       " 'high',\n",
       " 'number',\n",
       " 'key',\n",
       " 'computer',\n",
       " 'clipper',\n",
       " 'make',\n",
       " 'like',\n",
       " 'may',\n",
       " 'believe',\n",
       " 'work',\n",
       " 'truth',\n",
       " 'give',\n",
       " 'christianity',\n",
       " 'go',\n",
       " 'find',\n",
       " 'hell',\n",
       " 'use',\n",
       " 'reason',\n",
       " 'law',\n",
       " 'true',\n",
       " 'even',\n",
       " 'christ',\n",
       " 'take',\n",
       " 'life',\n",
       " 'get',\n",
       " 'people',\n",
       " 'thing',\n",
       " 'way',\n",
       " 'faith',\n",
       " 'mean',\n",
       " 'university',\n",
       " 'church',\n",
       " 'god',\n",
       " 'sin',\n",
       " 'word',\n",
       " 'first',\n",
       " 'child',\n",
       " 'two',\n",
       " 'turkish',\n",
       " 'gun',\n",
       " 'year',\n",
       " 'armenian',\n",
       " 'writes',\n",
       " 'tell',\n",
       " 'jew',\n",
       " 'israel',\n",
       " 'call',\n",
       " 'israeli',\n",
       " 'mr',\n",
       " 'kill']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1., 1000., 1000., 1000.,    1.,    1.,    1.,    1.,    1.,\n",
       "          1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = np.ones(10)\n",
    "temp1[np.array([1,2,3])] = 1000\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-270dee31759d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "temp1[np.array([])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006737946999085467"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = -10\n",
    "c = 3\n",
    "\n",
    "b = 0.8\n",
    "\n",
    "np.exp(a*b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006737946999085458"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(c) * np.exp(b)**a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2457309396155174"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c**(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.953032424395115, 1.2214027581601699)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "b = 0.8\n",
    "c = 0.1\n",
    "np.exp(a)**b, np.exp(a)**c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
