{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "cv = CountVectorizer()\n",
    "_dir = \"/Users/shinbo/Desktop/metting/LDA/0. data/20news-bydate/newsgroup_preprocessed.pickle\"\n",
    "\n",
    "\n",
    "class LDA_sklearn:\n",
    "    def __init__(self, path_data, alpha, eta, K):\n",
    "        # loading data\n",
    "        self.data = pickle.load(open(path_data, 'rb'))\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.choice(len(self.data), 1000, replace=False)\n",
    "        self.data = [j for i, j in enumerate(self.data) if i in idx]\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "\n",
    "    def _make_vocab(self):\n",
    "        self.vocab = []\n",
    "        for lst in self.data:\n",
    "            self.vocab += lst\n",
    "        self.vocab = sorted(list(set(self.vocab)))\n",
    "        self.w2idx = {j: i for i, j in enumerate(self.vocab)}\n",
    "        self.idx2w = {val: key for key, val in self.w2idx.items()}\n",
    "        self.doc2idx = [[self.w2idx[word] for word in doc] for doc in self.data]\n",
    "        self.data = [' '.join(doc) for doc in self.data]\n",
    "\n",
    "    def _cv(self):\n",
    "        self._make_vocab()\n",
    "        self.cv = CountVectorizer()\n",
    "        self.df = self.cv.fit_transform(self.data)\n",
    "\n",
    "    def _train(self):\n",
    "        self._make_vocab\n",
    "        self._cv()\n",
    "        lda = LatentDirichletAllocation(n_components=self.K, \n",
    "                                        doc_topic_prior=self.alpha, topic_word_prior=self.eta,\n",
    "                                        learning_method='batch', max_iter=1000)\n",
    "        lda.fit(self.df)\n",
    "        return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA_sklearn(_dir, 5, 0.1, 10)\n",
    "result = lda._train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "right 204.85 | game 150.91 | people 144.01 | writes 143.6 | would 141.26 | well 137.47 | year 122.36 | article 113.84 | team 105.81 | government 103.5 | \n",
      "\n",
      "Topic Nr.2:\n",
      "say 170.88 | said 165.65 | one 134.63 | go 113.25 | people 112.32 | going 96.85 | day 91.28 | dont 89.25 | time 86.39 | well 81.59 | \n",
      "\n",
      "Topic Nr.3:\n",
      "god 267.02 | think 180.35 | believe 156.47 | one 156.11 | would 147.44 | say 118.72 | people 113.65 | thing 104.36 | dont 103.54 | like 102.93 | \n",
      "\n",
      "Topic Nr.4:\n",
      "key 179.45 | system 159.33 | also 107.91 | keyboard 97.06 | one 83.19 | price 82.14 | pc 75.4 | access 74.23 | de 73.55 | use 68.74 | \n",
      "\n",
      "Topic Nr.5:\n",
      "writes 163.52 | article 141.53 | one 126.43 | israel 98.1 | subject 96.38 | israeli 90.1 | would 89.81 | like 88.32 | number 83.49 | line 76.8 | \n",
      "\n",
      "Topic Nr.6:\n",
      "or 302.1 | do 121.04 | mr 59.5 | font 57.1 | subject 52.99 | help 52.64 | um 44.1 | organization 38.8 | world 37.09 | looking 36.37 | \n",
      "\n",
      "Topic Nr.7:\n",
      "line 407.15 | organization 293.7 | subject 284.25 | nntppostinghost 231.67 | drive 174.1 | computer 127.14 | problem 126.67 | card 125.1 | university 117.31 | good 114.3 | \n",
      "\n",
      "Topic Nr.8:\n",
      "subject 345.66 | line 339.4 | organization 326.72 | university 227.72 | nntppostinghost 129.99 | writes 120.05 | would 75.49 | anyone 74.78 | article 70.45 | unit 69.87 | \n",
      "\n",
      "Topic Nr.9:\n",
      "would 188.81 | ca 122.95 | article 122.37 | one 119.88 | car 115.32 | dont 110.51 | like 106.83 | gun 101.98 | time 100.82 | people 88.69 | \n",
      "\n",
      "Topic Nr.10:\n",
      "window 302.81 | file 291.98 | image 216.1 | jpeg 208.1 | program 173.59 | get 168.17 | version 165.11 | use 129.45 | available 128.65 | information 126.61 | \n"
     ]
    }
   ],
   "source": [
    "lda_lam = [result.components_[i,:] for i in range(10)]\n",
    "\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda_lam, list(lda.cv.get_feature_names()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('lda_model.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Nr.1:\n",
      "line 867.85 | subject 739.78 | organization 700.42 | university 409.2 | nntppostinghost 360.69 | distribution 233.85 | anyone 216.1 | please 200.1 | computer 187.51 | new 182.84 | \n",
      "\n",
      "Topic Nr.2:\n",
      "would 634.36 | like 449.24 | good 230.19 | think 227.23 | get 218.78 | people 187.47 | im 174.78 | much 160.13 | thing 143.79 | make 132.07 | \n",
      "\n",
      "Topic Nr.3:\n",
      "question 253.1 | may 211.09 | get 170.17 | group 162.1 | one 161.26 | also 145.68 | find 134.79 | article 127.63 | course 114.1 | answer 107.1 | \n",
      "\n",
      "Topic Nr.4:\n",
      "well 212.85 | year 196.81 | right 161.84 | game 159.1 | point 143.42 | team 137.1 | second 123.1 | state 112.31 | last 100.14 | every 100.1 | \n",
      "\n",
      "Topic Nr.5:\n",
      "writes 504.76 | article 450.11 | organization 311.78 | line 292.35 | subject 273.38 | replyto 122.12 | world 110.81 | david 104.93 | space 95.32 | research 93.1 | \n",
      "\n",
      "Topic Nr.6:\n",
      "window 343.1 | file 308.1 | use 258.33 | system 224.77 | image 216.1 | program 213.1 | jpeg 208.1 | version 190.1 | information 180.1 | available 164.1 | \n",
      "\n",
      "Topic Nr.7:\n",
      "dont 344.01 | one 305.96 | go 298.1 | say 279.76 | said 224.1 | know 207.5 | still 184.1 | car 151.1 | take 143.4 | well 130.35 | \n",
      "\n",
      "Topic Nr.8:\n",
      "people 167.89 | key 166.25 | could 149.61 | government 134.1 | make 126.65 | dont 117.57 | one 115.9 | part 109.91 | give 108.32 | used 108.21 | \n",
      "\n",
      "Topic Nr.9:\n",
      "or 302.1 | drive 174.1 | problem 163.93 | do 143.1 | card 125.1 | hard 104.1 | bit 95.49 | disk 95.1 | scsi 82.1 | mr 80.1 | \n",
      "\n",
      "Topic Nr.10:\n",
      "god 272.1 | believe 167.1 | one 144.52 | ca 139.1 | science 133.1 | think 130.97 | gun 111.1 | life 110.1 | person 95.1 | word 89.35 | \n"
     ]
    }
   ],
   "source": [
    "lda_lam = [model.lam[:,k] for k in range(10)]\n",
    "def print_top_words(lam, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(lam):\n",
    "        print('\\nTopic Nr.%d:' % int(topic_id + 1))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "                       + ' | ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda_lam, list(model.cv.get_feature_names()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473.5030612993274, 165.96644608870963, 164.58448665312082, 164.31820617487926, 164.2323556293911, 164.19539253285754, 164.17206435577862, 164.15392484743478, 164.14119950109372, 164.12841210838496, 164.12143814942982, 164.1196620103764, 164.11414938972212, 164.11270673994284, 164.1126734963347, 164.11266403426097]\n",
      "[-877194.2326908677, -727908.0509850737, -726717.375740957, -726486.8041059296, -726412.3866635272, -726380.334127943, -726360.1013935744, -726344.3668504879, -726333.3276133211, -726322.2336887941, -726316.1829453944, -726314.6418912802, -726309.858799906, -726308.6070410116, -726308.5781960557, -726308.569985962]\n"
     ]
    }
   ],
   "source": [
    "print(model.perplexity)\n",
    "print(model._ELBO_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
